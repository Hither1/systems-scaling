# data:
#   paths:
  # - fineweb-100b
  # - starcoder
  # - proof-pile-2
  # - fineweb-edu-100b
  # - slimpajama-chunk1
  # - smollm-corpus

training:
  batch_size: 1024 # global_train_batch_size
  
save_interval: 1000
save_interval_unsharded: 100000
save_num_checkpoints_to_keep: 1
save_num_unsharded_checkpoints_to_keep: 1
sweep:
- device_eval_batch_size: 64
  device_train_microbatch_size: 128
  eval_interval: 650
  max_duration: 3254
  model:
    d_model: 256
    context_length: 512
    n_heads: 4
    n_layers: 4
  scheduler:
    t_warmup: 650
  total_flops: 200000000000000000
wandb:
  group: new-scale-big-1
